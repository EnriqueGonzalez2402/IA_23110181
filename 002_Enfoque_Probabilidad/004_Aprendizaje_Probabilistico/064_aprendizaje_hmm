# Entrenamiento (Baum-Welch / EM) de un HMM con emisiones discretas
# - Modelo: N estados ocultos, M símbolos observables
# - Entradas: secuencia(s) de observaciones (discretas, 0..M-1)
# - Salida: estimación de pi (inicial), A (transición), B (emisión)
# ----------------------------------------------------
import numpy as np

np.random.seed(0)

# ---------- Crear datos sintéticos ----------
# Verdadero HMM (para generar datos)
true_pi = np.array([0.6, 0.4])  # prob. inicial
true_A = np.array([[0.7, 0.3],
                   [0.4, 0.6]])  # transiciones
true_B = np.array([[0.6, 0.3, 0.1],   # estado 0 emite símbolo 0,1,2
                   [0.1, 0.3, 0.6]])  # estado 1

def generate_sequence(length, pi, A, B):
    """Genera una secuencia observada y la secuencia oculta correspondiente."""
    N = len(pi)
    M = B.shape[1]
    states = []
    obs = []
    # escoger estado inicial
    s = np.random.choice(N, p=pi)
    states.append(s)
    obs.append(np.random.choice(M, p=B[s]))
    for _ in range(1, length):
        s = np.random.choice(N, p=A[s])
        states.append(s)
        obs.append(np.random.choice(M, p=B[s]))
    return np.array(states), np.array(obs)

# generamos varias secuencias de entrenamiento
sequences = []
for _ in range(50):
    _, obs = generate_sequence(30, true_pi, true_A, true_B)
    sequences.append(obs)

# ---------- Inicialización del modelo (aleatoria) ----------
N = 2  # número de estados ocultos (desconocido en práctica; aquí lo fijamos)
M = 3  # número de símbolos observables
pi = np.full(N, 1.0/N) + 0.01 * np.random.rand(N)
pi /= pi.sum()
A = np.random.rand(N, N)
A /= A.sum(axis=1, keepdims=True)
B = np.random.rand(N, M)
B /= B.sum(axis=1, keepdims=True)

# ---------- Funciones auxiliares: forward / backward ----------
def forward(obs, pi, A, B):
    T = len(obs)
    N = A.shape[0]
    alpha = np.zeros((T, N))
    alpha[0] = pi * B[:, obs[0]]
    for t in range(1, T):
        for j in range(N):
            alpha[t, j] = B[j, obs[t]] * np.sum(alpha[t-1] * A[:, j])
    return alpha

def backward(obs, A, B):
    T = len(obs)
    N = A.shape[0]
    beta = np.zeros((T, N))
    beta[-1] = 1.0
    for t in range(T-2, -1, -1):
        for i in range(N):
            beta[t, i] = np.sum(A[i, :] * B[:, obs[t+1]] * beta[t+1, :])
    return beta

# ---------- Baum-Welch (EM) ----------
max_iter = 50
for iteration in range(max_iter):
    # acumuladores para reestimación
    pi_num = np.zeros(N)
    A_num = np.zeros((N, N))
    A_den = np.zeros(N)
    B_num = np.zeros((N, M))
    B_den = np.zeros(N)

    log_likelihood = 0.0

    for obs in sequences:
        T = len(obs)
        alpha = forward(obs, pi, A, B)
        beta = backward(obs, A, B)

        # probabilidad de la secuencia (evidencia)
        p_obs = alpha[-1].sum()
        log_likelihood += np.log(p_obs + 1e-12)

        # gamma_t(i) = P(state_t = i | observations)
        gamma = (alpha * beta) / (alpha * beta).sum(axis=1, keepdims=True)

        # xi_t(i,j) = P(state_t=i, state_{t+1}=j | observations)
        xi = np.zeros((T-1, N, N))
        for t in range(T-1):
            denom = np.sum(alpha[t][:, None] * A * B[:, obs[t+1]] * beta[t+1][None, :])
            if denom == 0:
                denom = 1e-12
            xi[t] = (alpha[t][:, None] * A * B[:, obs[t+1]] * beta[t+1][None, :]) / denom

        # acumular para pi
        pi_num += gamma[0]

        # acumular para A
        A_num += xi.sum(axis=0)
        A_den += gamma[:-1].sum(axis=0)

        # acumular para B
        for k in range(M):
            mask = (obs == k)
            B_num[:, k] += gamma[mask].sum(axis=0)
        B_den += gamma.sum(axis=0)

    # reestimación
    pi = pi_num / pi_num.sum()
    # evitar división por cero
    A = A_num / (A_num.sum(axis=1, keepdims=True) + 1e-12)
    B = B_num / (B_num.sum(axis=1, keepdims=True) + 1e-12)

    if iteration % 10 == 0 or iteration == max_iter-1:
        print(f"Iter {iteration:02d}: log-likelihood = {log_likelihood:.3f}")

print("\nEstimación final:")
print("pi:", pi)
print("A:\n", A)
print("B:\n", B)

# Nota: para datos reales y mayor robustez, usar bibliotecas optimizadas (hmmlearn).